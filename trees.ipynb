{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trees.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/albert-yue/gcn-explanability/blob/master/gcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"A11y364X-9jl","colab_type":"code","outputId":"56b4e6f5-336c-4b90-a129-aaf31b83a22f","executionInfo":{"status":"ok","timestamp":1588963328476,"user_tz":420,"elapsed":29156,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ndu7rVIEZcrZ","colab_type":"code","outputId":"65df7981-5d7c-49ca-ce8a-4c59c1c35c20","executionInfo":{"status":"ok","timestamp":1588963339699,"user_tz":420,"elapsed":520,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd gdrive/My\\ Drive/gcn_explainability"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/gcn_explainability\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eiUpBzRmQMfE","colab_type":"code","colab":{}},"source":["! git config --global user.email \"ecrainbow8@gmail.com\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Df_-n0RZZsTT","colab_type":"code","outputId":"191c41cb-31b2-4666-d763-9359d30e5434","executionInfo":{"status":"ok","timestamp":1588892857465,"user_tz":420,"elapsed":1589,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["[master bbef074] Update\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6NEViyYwCVuN","colab_type":"code","outputId":"4ccf7d00-d3d4-4aab-db81-a3706b092137","executionInfo":{"status":"ok","timestamp":1588484207143,"user_tz":420,"elapsed":1180,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/  gcn.ipynb  logs.pt  \u001b[01;34mnotebooks\u001b[0m/  README.md  \u001b[01;34msrc\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OtjGyOBHAGys","colab_type":"code","outputId":"29e64faf-5254-410d-e8ca-1a1ab411d79e","executionInfo":{"status":"ok","timestamp":1588963985317,"user_tz":420,"elapsed":643138,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["from src.models.gcn import GCNTreebankModel\n","import torch\n","import numpy as np\n","import scipy.sparse as sparse\n","import scipy\n","from src.data import Corpus, get_data, get_labels, get_vocabulary\n","from src.utils import load_sparse_tensor\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from src.preprocessing import build_adj_matrix, normalize_adj\n","from src.stanford_preprocessing import load_glove_embeddings\n","\n","logs = (200, 0.5, 41664, 23, 'logs.pt')\n","ng20 = (200, 0.5, 80035, 20, 'gcn_20ng_full.pt', 61189, 18846, 11314,7532)\n","trees = ('sst_train_tune_hidden_30_lr_0.00015.pt', 200, 30 ,5, 0.5)\n","path, input_size, hidden_size, output_size, dropout = trees\n","\n","model = GCNTreebankModel(input_size, hidden_size, output_size, dropout)\n","\n","\n","model.load_state_dict(torch.load(path))\n","print(\"hi\")\n","test_data = torch.load(\"data/stanford_test.pt\")\n","inputs = test_data['inputs']\n","print(inputs[0].label)\n","embeddings = torch.load(\"data/embeddings.pt\")\n","print(embeddings)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["hi\n","2\n"],"name":"stdout"},{"output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eSxaphYGa6iH","colab_type":"code","outputId":"14551868-9aa2-441e-8367-07b1299a011f","executionInfo":{"status":"ok","timestamp":1588896195384,"user_tz":420,"elapsed":553,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# reverse_map = {}\n","# for word, embedding in embeddings.items():\n","#   reverse_map[embedding] = word\n","\n","# print(len(embeddings.items()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["401784\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xgfSNO_Jl-jR","colab_type":"code","colab":{}},"source":["treebank = test_data['treebank']\n","def getLeft(node):\n","  if node.children:\n","    return getLeft(node.children[0])\n","  else:\n","    return node.text\n","def getRight(node):\n","  if node.children:\n","    return getRight(node.children[-1])\n","  else:\n","    return node.text\n","\n","def node_to_words(node, words=[]):\n","  if node.children:\n","    node_to_words(node.children[0], words)\n","    words.append(getLeft(node) + \" --- \" + getRight(node))\n","    if (len(node.children) == 2):\n","      node_to_words(node.children[1], words)\n","    return words\n","  else:\n","    words.append(node.text)\n","    return words\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jTx9ZBaUEqI","colab_type":"code","colab":{}},"source":["def matrices(path, adj, inp, label):\n","  model = GCNTreebankModel(input_size, hidden_size, output_size, dropout)\n","  model.load_state_dict(torch.load(path))\n","  model.eval()\n","  loss_fn = nn.CrossEntropyLoss()\n","  model.zero_grad()\n","  output = model(adj, inp)\n","  loss = loss_fn(output, label)\n","  loss.retain_grad()\n","  loss.backward()\n","  weight_matrices = []\n","  gradients = []\n","  for n, p in model.named_parameters():\n","    print(n)\n","    weight_matrices.append(p.detach().numpy())\n","    gradients.append(p.grad.numpy())\n","  return weight_matrices, gradients, output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Om_3PKBAV3AI","colab_type":"code","colab":{}},"source":["def grad_cam_avg(adj, inp, weight_matrices, gradients):\n","  V = np.matmul(adj, inp)\n","  F_1 = scipy.special.expit(np.matmul(V, weight_matrices[0]))\n","  F_2 = scipy.special.expit(np.matmul(V, np.matmul(inp.T, (np.matmul(F_1, weight_matrices[1])))))\n","  F = [F_1, F_2]\n","  grad_cams = []\n","  for l in range(2):\n","      grad_cam = []\n","      grad_cams.append(grad_cam)\n","      alphas = np.mean(gradients[l], axis = 0)\n","      for n in range(adj.shape[0]):\n","        grad_cam.append(np.maximum(0, np.dot(alphas, F[l][n, :])))\n","\n","  grad_cam_avgs = np.mean(grad_cams, axis=0)\n","  return grad_cams, grad_cam_avgs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GG8cusL0x5YL","colab_type":"code","colab":{}},"source":["def convert_to_words(top_words, sentence_words):\n","  words = []\n","  for embedding in top_words:\n","      words.append(sentence_words[embedding])\n","  return words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yk6sl20GWRqN","colab_type":"code","outputId":"647c7ded-4908-4194-d8c5-946e88ec0ffa","executionInfo":{"status":"ok","timestamp":1588966981185,"user_tz":420,"elapsed":596,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["indices = [6, 493]\n","for i in indices:\n","  single_corpus = inputs[i]\n","  sentence = treebank[i].text\n","  node_words = node_to_words(treebank[i].tree, [])\n","  adj = single_corpus.adj\n","  label = torch.LongTensor([single_corpus.label])\n","  inp = single_corpus.inp\n","  weight_matrices, gradients, output = matrices(path, adj, inp, label)\n","  grad_cams, grad_cam_avgs = grad_cam_avg(adj, inp, weight_matrices, gradients)\n","  print(sentence)\n","  print(label)\n","  print(np.argmax(output.detach().numpy()))\n","  for name, grad_cam_vals in [('layer1', grad_cams[0]), ('layer2', grad_cams[1]), ('overall', grad_cam_avgs)]:\n","    print(name+\":\\n\")\n","    top_words_idx = np.asarray(grad_cam_vals).argsort()[-10:]\n","    top_words = convert_to_words(reversed(top_words_idx), node_words)\n","    for word in top_words:\n","      print(word)\n","  \n","  \n","  max_grads = np.asarray(np.linalg.norm(np.matmul(inp,np.matmul(gradients[0], gradients[1])),axis=1)).argsort()[-10:]\n","  print(convert_to_words(reversed(max_grads), node_words))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["layer1.weight\n","layer2.weight\n","['Steers', 'turns', 'in', 'a', 'snappy', 'screenplay', 'that', 'curls', 'at', 'the', 'edges', ';', 'it', \"'s\", 'so', 'clever', 'you', 'want', 'to', 'hate', 'it', '.']\n","tensor([3])\n","3\n","layer1:\n","\n",".\n","screenplay\n","the\n","at --- edges\n","at\n","curls --- edges\n","curls\n","that --- edges\n","that\n","a --- edges\n","layer2:\n","\n","Steers\n","screenplay\n","curls\n","snappy\n","the\n","at --- edges\n","at\n","curls --- edges\n","that --- edges\n","that\n","overall:\n","\n","Steers\n","screenplay\n","curls\n","snappy\n","the\n","at --- edges\n","at\n","curls --- edges\n","that --- edges\n","that\n","['it --- it', 'you --- it', 'so --- it', 'to --- it', \"'s --- it\", 'want --- it', 'that --- edges', 'a --- edges', 'the --- edges', 'in --- edges']\n","layer1.weight\n","layer2.weight\n","['This', 'boisterous', 'comedy', 'serves', 'up', 'a', 'cruel', 'reminder', 'of', 'the', 'fate', 'of', 'hundreds', 'of', 'thousands', 'of', 'Chinese', ',', 'one', 'which', 'can', 'only', 'qualify', 'as', 'a', 'terrible', 'tragedy', '.']\n","tensor([2])\n","3\n","layer1:\n","\n","a --- tragedy\n","the --- tragedy\n","hundreds --- tragedy\n","Chinese --- tragedy\n","of --- tragedy\n","of --- tragedy\n","of\n","of\n","of\n","cruel --- reminder\n","layer2:\n","\n",".\n","cruel --- reminder\n","hundreds\n","of --- tragedy\n","of\n","the --- tragedy\n","fate\n","the --- fate\n","the\n","of --- tragedy\n","overall:\n","\n","a --- tragedy\n","the --- tragedy\n","hundreds --- tragedy\n","Chinese --- tragedy\n","of --- tragedy\n","of --- tragedy\n","of\n","of\n","of\n","cruel --- reminder\n","['of --- tragedy', 'of --- tragedy', 'of --- tragedy', 'the --- tragedy', 'a --- tragedy', 'a --- tragedy', 'one --- tragedy', 'which --- tragedy', 'terrible --- tragedy', 'Chinese --- tragedy']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QdwXvsuMona5","colab_type":"code","outputId":"7363fe1b-4feb-477a-81f0-a0e4b4fb3d3d","executionInfo":{"status":"ok","timestamp":1588898805758,"user_tz":420,"elapsed":566,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["\n","\n","total = 0\n","max_num = 10\n","for i in range(1, 7500):\n","  model.eval()\n","  model.zero_grad()\n","  output = model(inputs[i].adj, inputs[i].inp)\n","  if inputs[i].label == np.argmax(output.detach().numpy()):\n","    print(i)\n","    total += 1\n","    if total == max_num:\n","      break\n","\n","total = 0\n","for i in range(1, 1000):\n","  model.eval()\n","  model.zero_grad()\n","  output = model(inputs[i].adj, inputs[i].inp)\n","  if inputs[i].label == np.argmax(output.detach().numpy()):\n","    total += 1\n","print(total/1000)\n","\n","total = 0\n","for i in range(500, 1, -1):\n","  model.eval()\n","  model.zero_grad()\n","  output = model(inputs[i].adj, inputs[i].inp)\n","  if inputs[i].label != np.argmax(output.detach().numpy()):\n","    print(i)\n","    total += 1\n","    if total == max_num:\n","      break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4\n","6\n","8\n","9\n","10\n","11\n","12\n","14\n","17\n","19\n","0.424\n","500\n","499\n","498\n","497\n","493\n","491\n","490\n","489\n","486\n","482\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hbDNPhjAq8lH","colab_type":"code","outputId":"e12684b7-cc7b-4402-844e-d1df1ca2f499","executionInfo":{"status":"ok","timestamp":1588967003456,"user_tz":420,"elapsed":524,"user":{"displayName":"Erica Chiu","photoUrl":"https://lh3.googleusercontent.com/-M45l6bCV3_A/AAAAAAAAAAI/AAAAAAAAABM/Qu5eyrsuWhc/s64/photo.jpg","userId":"09442177969168552567"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["def p_carrot_val(carrot, p, weight_matrix):\n","  p_carrot = np.matmul(np.maximum(0, weight_matrix), carrot.T)\n","  p_carrot = p_carrot / np.sum(p_carrot.numpy(), axis= 0)\n","  p_carrot = np.matmul(p_carrot, p)\n","  return p_carrot\n","\n","def p_F_val(v, F, p_carrot):\n","  p_F = np.matmul(v, F)\n","  p_F = p_F / np.sum(p_F.numpy(), axis= 0)\n","  p_F = np.matmul(p_F, p_carrot.T)\n","  return p_F\n","\n","def EB(adj, inp, weight_matrices, gradients, output):\n","  V = np.matmul(adj, inp)\n","  V_ = np.matmul(inp.T, V)\n","  F_1 = scipy.special.expit(np.matmul(V_, weight_matrices[0]))\n","  F_2 = scipy.special.expit(np.matmul(V_, np.matmul(F_1, weight_matrices[1])))\n","  F = [F_1, F_2]\n","  F_carrot = [np.matmul(V_, F_1), np.matmul(V_, F_2)]\n","  p_F3 = np.tile(output.detach().numpy(), (inp.shape[1],1))\n","  p_carrot_F2 = p_carrot_val(F_carrot[1], p_F3, weight_matrices[1])\n","  p_F2 = p_F_val(V_, F[1], p_carrot_F2)\n","  p_carrot_F1 = p_carrot_val(F_carrot[0], p_F2, weight_matrices[0])\n","  p_F1 = p_F_val(V, F[0], p_carrot_F1)\n","  p_F = [p_F1, p_F2, p_F3]\n","  p_carrot_F = [p_carrot_F1, p_carrot_F2]\n","  eb_vals = np.mean(p_F1.numpy(), axis=1)\n","  return eb_vals\n","\n","\n","for i in indices:\n","  single_corpus = inputs[i]\n","  sentence = treebank[i].text\n","  node_words = node_to_words(treebank[i].tree, [])\n","  adj = single_corpus.adj\n","  label = torch.LongTensor([single_corpus.label])\n","  inp = single_corpus.inp\n","  weight_matrices, gradients, output = matrices(path, adj, inp, label)\n","  eb_vals = EB(adj, inp, weight_matrices, gradients, output)\n","\n","\n","  print(sentence)\n","  print(label)\n","  print(np.argmax(output.detach().numpy()))\n","  top_words_idx = np.asarray(grad_cam_vals).argsort()[-10:]\n","  top_words = convert_to_words(reversed(top_words_idx), node_words)\n","  for word in top_words:\n","    print(word)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["layer1.weight\n","layer2.weight\n","['Steers', 'turns', 'in', 'a', 'snappy', 'screenplay', 'that', 'curls', 'at', 'the', 'edges', ';', 'it', \"'s\", 'so', 'clever', 'you', 'want', 'to', 'hate', 'it', '.']\n","tensor([3])\n","3\n","curls --- edges\n","Steers --- ;\n","so --- it\n","want --- it\n","clever --- it\n","Steers --- it\n","at\n","clever\n",";\n","that --- edges\n","layer1.weight\n","layer2.weight\n","['This', 'boisterous', 'comedy', 'serves', 'up', 'a', 'cruel', 'reminder', 'of', 'the', 'fate', 'of', 'hundreds', 'of', 'thousands', 'of', 'Chinese', ',', 'one', 'which', 'can', 'only', 'qualify', 'as', 'a', 'terrible', 'tragedy', '.']\n","tensor([2])\n","3\n","a --- tragedy\n","the --- tragedy\n","hundreds --- tragedy\n","Chinese --- tragedy\n","of --- tragedy\n","of --- tragedy\n","of\n","of\n","of\n","cruel --- reminder\n"],"name":"stdout"}]}]}